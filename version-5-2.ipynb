{"cells":[{"cell_type":"code","execution_count":19,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2025-04-19T01:34:48.051207Z","iopub.status.busy":"2025-04-19T01:34:48.050605Z","iopub.status.idle":"2025-04-19T01:34:48.059710Z","shell.execute_reply":"2025-04-19T01:34:48.058875Z","shell.execute_reply.started":"2025-04-19T01:34:48.051183Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/deep-learning-spring-2025-project-2/test_unlabelled.pkl\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2025-04-19T01:34:48.061465Z","iopub.status.busy":"2025-04-19T01:34:48.060959Z","iopub.status.idle":"2025-04-19T01:34:48.093888Z","shell.execute_reply":"2025-04-19T01:34:48.093215Z","shell.execute_reply.started":"2025-04-19T01:34:48.061449Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]}],"source":["import torch\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n","from datasets import load_dataset, Dataset\n","from peft import get_peft_model, LoraConfig, TaskType\n","from sklearn.metrics import accuracy_score\n","import numpy as np\n","import pandas as pd\n","import pickle\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2025-04-19T01:34:48.094826Z","iopub.status.busy":"2025-04-19T01:34:48.094637Z","iopub.status.idle":"2025-04-19T01:35:12.363623Z","shell.execute_reply":"2025-04-19T01:35:12.362614Z","shell.execute_reply.started":"2025-04-19T01:34:48.094812Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"25c5eae366c7459a89747f1a7ab6f306","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/120000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"400c8e12353a4da79ca1a4a53b6faed5","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/7600 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["dataset = load_dataset(\"ag_news\")\n","tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\", add_prefix_space=True)\n","\n","def tokenize_function(examples):\n","    texts = [text.replace('\\n', ' ').strip() for text in examples[\"text\"]]\n","    texts = [text.replace('&quot;', '\"').replace('&apos;', \"'\").replace('&amp;', '&') for text in texts]\n","    \n","    return tokenizer(\n","        texts, \n","        truncation=True, \n","        padding=\"max_length\", \n","        max_length=128,  \n","        return_tensors=\"pt\"\n","    )\n","\n","# Apply tokenization to the dataset\n","tokenized_dataset = dataset.map(tokenize_function, batched=True)\n","tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n","tokenized_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2025-04-19T01:35:12.366368Z","iopub.status.busy":"2025-04-19T01:35:12.366085Z","iopub.status.idle":"2025-04-19T01:35:12.772456Z","shell.execute_reply":"2025-04-19T01:35:12.771785Z","shell.execute_reply.started":"2025-04-19T01:35:12.366342Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["trainable params: 999,172 || all params: 125,647,880 || trainable%: 0.7952\n"]}],"source":["model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=4)\n","\n","# Configure the LoRA adapter\n","lora_config = LoraConfig(\n","    r=4,  \n","    lora_alpha=16,  # Set alpha for smoother adjustments\n","    target_modules=[\"query\",\"value\",\"output.dense\"],  # Applying LoRA to layers\n","    lora_dropout=0.05,  # Keeps dropout to regularize the adaptation\n","    bias=\"none\",  \n","    task_type=TaskType.SEQ_CLS  # Sequence classification task\n",")\n","\n","# Attach the LoRA adapter to the model\n","model = get_peft_model(model, lora_config)\n","model.to(device)\n","model.print_trainable_parameters()"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2025-04-19T01:35:12.774822Z","iopub.status.busy":"2025-04-19T01:35:12.774603Z","iopub.status.idle":"2025-04-19T01:35:12.807060Z","shell.execute_reply":"2025-04-19T01:35:12.806562Z","shell.execute_reply.started":"2025-04-19T01:35:12.774805Z"},"trusted":true},"outputs":[],"source":["training_args = TrainingArguments(\n","    output_dir=\"./results\",  # Directory to store results\n","    eval_strategy=\"epoch\",  # Evaluate at the end of each epoch\n","    save_strategy=\"epoch\",  # Save model after every epoch\n","    learning_rate=3e-5,  # Adjusted learning rate for faster convergence\n","    per_device_train_batch_size=8,  # Adjusted batch size for stability\n","    per_device_eval_batch_size=64,  # Evaluation batch size\n","    num_train_epochs=3,  # Increased epochs to train more thoroughly\n","    weight_decay=0.01,  # Regularization to prevent overfitting\n","    logging_dir=\"./logs\",  # Log directory for tracking\n","    load_best_model_at_end=True,  # Load the best model at the end\n","    metric_for_best_model=\"accuracy\",  # Use accuracy for model selection\n","    report_to=\"none\",  # Disable logging to external services\n","    lr_scheduler_type=\"cosine_with_restarts\",\n","    label_smoothing_factor=0.05,\n","    warmup_ratio=0.15,\n","    eval_steps=500,\n","    save_steps=500,\n","    logging_steps=100,\n","    optim=\"adamw_torch\",  \n","    adam_beta1=0.9,\n","    adam_beta2=0.999,\n","    adam_epsilon=1e-8,\n","    greater_is_better=True,\n","    bf16=True,\n","    gradient_accumulation_steps=4  # Add gradient accumulation for stability\n",")\n","\n","# Function to compute accuracy during evaluation\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=-1)\n","    return {\"accuracy\": accuracy_score(labels, predictions)}"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2025-04-19T01:35:12.808237Z","iopub.status.busy":"2025-04-19T01:35:12.807965Z","iopub.status.idle":"2025-04-19T01:35:12.854772Z","shell.execute_reply":"2025-04-19T01:35:12.853957Z","shell.execute_reply.started":"2025-04-19T01:35:12.808216Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_31/1236968066.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n","No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"]}],"source":["trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_dataset[\"train\"],\n","    eval_dataset=tokenized_dataset[\"test\"],\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2025-04-19T01:35:12.855559Z","iopub.status.busy":"2025-04-19T01:35:12.855404Z","iopub.status.idle":"2025-04-19T03:06:40.264631Z","shell.execute_reply":"2025-04-19T03:06:40.263902Z","shell.execute_reply.started":"2025-04-19T01:35:12.855546Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='5625' max='5625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [5625/5625 1:31:25, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.404200</td>\n","      <td>0.399560</td>\n","      <td>0.917500</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.388100</td>\n","      <td>0.374885</td>\n","      <td>0.926711</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.366200</td>\n","      <td>0.371921</td>\n","      <td>0.928553</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=5625, training_loss=0.4537044475979275, metrics={'train_runtime': 5486.8882, 'train_samples_per_second': 65.611, 'train_steps_per_second': 1.025, 'total_flos': 2.39566712832e+16, 'train_loss': 0.4537044475979275, 'epoch': 3.0})"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2025-04-19T03:06:40.265670Z","iopub.status.busy":"2025-04-19T03:06:40.265441Z","iopub.status.idle":"2025-04-19T03:06:40.430815Z","shell.execute_reply":"2025-04-19T03:06:40.430233Z","shell.execute_reply.started":"2025-04-19T03:06:40.265652Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Model and tokenizer saved to saved_model\n","✅ Training arguments saved\n","✅ Model config saved\n"]}],"source":["output_dir = \"saved_model\"\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Save the model\n","model.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)\n","print(f\"✅ Model and tokenizer saved to {output_dir}\")\n","\n","# Save training arguments\n","import json\n","training_args_dict = training_args.to_dict()\n","with open(os.path.join(output_dir, \"training_args.json\"), \"w\") as f:\n","    json.dump(training_args_dict, f, indent=2)\n","print(\"✅ Training arguments saved\")\n","\n","# Save model config\n","model.config.save_pretrained(output_dir)\n","print(\"✅ Model config saved\")"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2025-04-19T03:06:40.431634Z","iopub.status.busy":"2025-04-19T03:06:40.431439Z","iopub.status.idle":"2025-04-19T03:06:41.385826Z","shell.execute_reply":"2025-04-19T03:06:41.385047Z","shell.execute_reply.started":"2025-04-19T03:06:40.431619Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["✅ Model and tokenizer loaded successfully\n"]}],"source":["from peft import PeftModel, PeftConfig\n","\n","# Load the saved config\n","config = PeftConfig.from_pretrained(\"saved_model\")\n","\n","# Load the base model\n","base_model = AutoModelForSequenceClassification.from_pretrained(\n","    \"roberta-base\",\n","    num_labels=4,\n","    device_map=\"auto\"\n",")\n","\n","# Load the fine-tuned model with adapters\n","loaded_model = PeftModel.from_pretrained(\n","    base_model,\n","    \"saved_model\",\n","    device_map=\"auto\"\n",")\n","\n","# Load the tokenizer\n","loaded_tokenizer = AutoTokenizer.from_pretrained(\"saved_model\")\n","\n","print(\"✅ Model and tokenizer loaded successfully\")"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2025-04-19T03:06:41.388205Z","iopub.status.busy":"2025-04-19T03:06:41.387953Z","iopub.status.idle":"2025-04-19T03:06:42.711154Z","shell.execute_reply":"2025-04-19T03:06:42.710359Z","shell.execute_reply.started":"2025-04-19T03:06:41.388186Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Loaded raw test dataset with 8000 examples\n","✅ Converted to HuggingFace Dataset format\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b515b0dd270e44cd9e715ce04dd03fb2","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["✅ Tokenization complete\n","✅ Created DataLoader with 125 batches\n"]}],"source":["from torch.utils.data import DataLoader\n","\n","with open(\"/kaggle/input/deep-learning-spring-2025-project-2/test_unlabelled.pkl\", \"rb\") as f:\n","    test_dataset = pickle.load(f)\n","print(f\"✅ Loaded raw test dataset with {len(test_dataset['text'])} examples\")\n","\n","# Convert to HuggingFace Dataset format\n","test_dataset = Dataset.from_dict({\"text\": test_dataset[\"text\"]})\n","print(\"✅ Converted to HuggingFace Dataset format\")\n","\n","# Tokenize test data\n","def preprocess_function(examples):\n","    return tokenizer(\n","        examples[\"text\"],\n","        truncation=True,\n","        padding=\"max_length\",\n","        max_length=128\n","    )\n","\n","tokenized_test = test_dataset.map(preprocess_function, batched=True)\n","tokenized_test.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n","print(\"✅ Tokenization complete\")\n","\n","# Create DataLoader for batched predictions\n","test_dataloader = DataLoader(tokenized_test, batch_size=64)\n","print(f\"✅ Created DataLoader with {len(test_dataloader)} batches\")"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2025-04-19T03:06:42.713196Z","iopub.status.busy":"2025-04-19T03:06:42.712963Z","iopub.status.idle":"2025-04-19T03:07:43.945985Z","shell.execute_reply":"2025-04-19T03:07:43.945399Z","shell.execute_reply.started":"2025-04-19T03:06:42.713180Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Starting prediction generation...\n","Total number of batches to process: 125\n","Processed batch 10/125 (8.0%)\n","Current predictions shape: 640\n","Sample predictions from this batch: [3 1 1 2 2]\n","--------------------------------------------------\n","Processed batch 20/125 (16.0%)\n","Current predictions shape: 1280\n","Sample predictions from this batch: [0 2 1 2 2]\n","--------------------------------------------------\n","Processed batch 30/125 (24.0%)\n","Current predictions shape: 1920\n","Sample predictions from this batch: [0 2 3 2 1]\n","--------------------------------------------------\n","Processed batch 40/125 (32.0%)\n","Current predictions shape: 2560\n","Sample predictions from this batch: [1 1 2 0 3]\n","--------------------------------------------------\n","Processed batch 50/125 (40.0%)\n","Current predictions shape: 3200\n","Sample predictions from this batch: [3 0 2 1 0]\n","--------------------------------------------------\n","Processed batch 60/125 (48.0%)\n","Current predictions shape: 3840\n","Sample predictions from this batch: [2 3 3 2 3]\n","--------------------------------------------------\n","Processed batch 70/125 (56.0%)\n","Current predictions shape: 4480\n","Sample predictions from this batch: [3 3 1 2 3]\n","--------------------------------------------------\n","Processed batch 80/125 (64.0%)\n","Current predictions shape: 5120\n","Sample predictions from this batch: [2 2 0 3 3]\n","--------------------------------------------------\n","Processed batch 90/125 (72.0%)\n","Current predictions shape: 5760\n","Sample predictions from this batch: [1 3 3 2 1]\n","--------------------------------------------------\n","Processed batch 100/125 (80.0%)\n","Current predictions shape: 6400\n","Sample predictions from this batch: [3 3 3 3 2]\n","--------------------------------------------------\n","Processed batch 110/125 (88.0%)\n","Current predictions shape: 7040\n","Sample predictions from this batch: [2 3 1 3 1]\n","--------------------------------------------------\n","Processed batch 120/125 (96.0%)\n","Current predictions shape: 7680\n","Sample predictions from this batch: [2 1 2 2 3]\n","--------------------------------------------------\n","Processed batch 125/125 (100.0%)\n","Current predictions shape: 8000\n","Sample predictions from this batch: [2 0 1 3 0]\n","--------------------------------------------------\n","\n","Prediction generation completed!\n","Total predictions generated: 8000\n","Unique classes predicted: [0 1 2 3]\n","Class distribution: \n","0    1552\n","1    2000\n","2    1827\n","3    2621\n","Name: count, dtype: int64\n"]}],"source":["print(\"Starting prediction generation...\")\n","model.eval()\n","all_predictions = []\n","\n","total_batches = len(test_dataloader)\n","print(f\"Total number of batches to process: {total_batches}\")\n","\n","with torch.no_grad():\n","    for batch_idx, batch in enumerate(test_dataloader, 1):\n","        batch = {k: v.to(device) for k, v in batch.items()}  # Move to GPU\n","        outputs = model(**batch)  # Generate logits\n","        predictions = torch.argmax(outputs.logits, dim=-1)  # Get predicted labels\n","        all_predictions.extend(predictions.cpu().numpy())  # Store predictions\n","        \n","        # Print progress at every 10th batch\n","        if batch_idx % 10 == 0 or batch_idx == total_batches:\n","            print(f\"Processed batch {batch_idx}/{total_batches} ({(batch_idx/total_batches*100):.1f}%)\")\n","            print(f\"Current predictions shape: {len(all_predictions)}\")\n","            print(f\"Sample predictions from this batch: {predictions[:5].cpu().numpy()}\")\n","            print(\"-\" * 50)\n","\n","print(\"\\nPrediction generation completed!\")\n","print(f\"Total predictions generated: {len(all_predictions)}\")\n","print(f\"Unique classes predicted: {np.unique(all_predictions)}\")\n","print(f\"Class distribution: \\n{pd.Series(all_predictions).value_counts().sort_index()}\")"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2025-04-19T03:07:43.946797Z","iopub.status.busy":"2025-04-19T03:07:43.946615Z","iopub.status.idle":"2025-04-19T03:07:43.979591Z","shell.execute_reply":"2025-04-19T03:07:43.979067Z","shell.execute_reply.started":"2025-04-19T03:07:43.946783Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["✅ Predictions saved to submission.csv\n"]}],"source":["df = pd.DataFrame({\n","    \"ID\": range(len(all_predictions)),\n","    \"label\": all_predictions\n","})\n","df.to_csv(\"submission.csv\", index=False)\n","print(\"✅ Predictions saved to submission.csv\")"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":11711500,"sourceId":98084,"sourceType":"competition"}],"dockerImageVersionId":31011,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"}},"nbformat":4,"nbformat_minor":4}
